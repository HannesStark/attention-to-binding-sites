{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HannesStark\\Anaconda3\\envs\\equibind\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (10,11,13,14,15,16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\HannesStark\\Anaconda3\\envs\\equibind\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (7,9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sn\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "\n",
    "sn.set_theme()\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "sn.set_style(\"whitegrid\")\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio import pairwise2\n",
    "\n",
    "anno = pd.read_csv('data/scraped_annotations.csv')\n",
    "binding_db = pd.read_csv('data/binding_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def realign(preds, truth, dist=2):\n",
    "    # Produce different shifts for the `preds` array\n",
    "    pad_preds = np.pad(preds, [(dist, dist)])\n",
    "    shift_preds = []\n",
    "    shift_array = np.concatenate([np.arange(-dist, 0), np.arange(1, dist + 1)])\n",
    "    for ii in shift_array:\n",
    "        this_preds = np.pad(pad_preds.copy(), [(0, 1)])\n",
    "        shift_preds.append(this_preds[dist - ii:-dist - ii - 1] * truth)\n",
    "\n",
    "    # Shift the `preds` array according to the maximum intersection with the truth\n",
    "    EPS = 1e-8\n",
    "    eps = np.zeros_like(shift_preds[0]) + EPS\n",
    "    shift_preds = np.stack([eps] + shift_preds, axis=0)\n",
    "    shift_idx = np.argmax(shift_preds, axis=0)\n",
    "    shift_idx[shift_idx == 0] = -1\n",
    "    shift_preds = np.concatenate([shift_preds, preds.reshape(1, *preds.shape)], axis=0)\n",
    "    preds2 = shift_preds[shift_idx, np.arange(shift_preds.shape[1])]\n",
    "\n",
    "    # Find the values that were shifted, and replace them by ~0\n",
    "    shift_factor = np.array([shift_array[idx - 1] if idx >= 0 else 0 for idx in shift_idx])\n",
    "    was_shifted = -shift_factor + np.arange(len(shift_factor))\n",
    "    was_shifted = was_shifted[shift_factor != 0]\n",
    "    preds2[was_shifted] = EPS\n",
    "\n",
    "    # In case of intersection with the truth, keep the highest value to prevent bad shifts\n",
    "    preds2[truth] = np.maximum(preds[truth], preds2[truth])\n",
    "    return preds2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def binding_site_annotation(alignments_input, has_target_frame, input_sequence):\n",
    "    is_binding_site = np.zeros(len(input_sequence))\n",
    "    for alignment, sequence, binding_sites in list(zip(alignments_input, has_target_frame['sequence'],\n",
    "                                                       has_target_frame['Binding site residues1'])):\n",
    "        if alignment.score < len(input_sequence) * alignment_ratio or alignment.score < len(\n",
    "                input_sequence) - misaligned_allowance: continue\n",
    "        acids = []\n",
    "        site_indices = []\n",
    "        for site in binding_sites.split():\n",
    "            acids.append(site[0])\n",
    "            site_indices.append(int(site[1:]) - 1)\n",
    "        reverse_indices = site_indices[::-1]\n",
    "        annotated_count = 0\n",
    "        to_annotate_count = 0\n",
    "        target_sequence = ''\n",
    "        target_sequence_annotations = ''\n",
    "        annotated_sequence_annotations = ''\n",
    "        annotated_sequence_annotations_manual = ''\n",
    "        align_annotation_annotated_sequence = ''\n",
    "        align_annotation_target = ''\n",
    "        for i in range(len(is_binding_site)):\n",
    "            if i in reverse_indices:\n",
    "                annotated_sequence_annotations += '1'\n",
    "            else:\n",
    "                annotated_sequence_annotations += '0'\n",
    "\n",
    "        for annotated, to_annotate in list(zip(alignment[1], alignment[0])):\n",
    "            if len(reverse_indices) == 0: break\n",
    "            is_binding_idx = False\n",
    "            if reverse_indices[-1] == annotated_count and annotated != '-':\n",
    "                reverse_indices.pop()\n",
    "                is_binding_idx = True\n",
    "\n",
    "            if to_annotate != '-':\n",
    "                if is_binding_idx:\n",
    "                    is_binding_site[to_annotate_count] = 1\n",
    "                    target_sequence_annotations += '1'\n",
    "                    align_annotation_target += '1'\n",
    "                else:\n",
    "                    target_sequence_annotations += '0'\n",
    "                    align_annotation_target += '0'\n",
    "                target_sequence += to_annotate\n",
    "                to_annotate_count += 1\n",
    "            else:\n",
    "                align_annotation_target += '-'\n",
    "\n",
    "            if annotated != '-':\n",
    "                if is_binding_idx:\n",
    "                    align_annotation_annotated_sequence += '1'\n",
    "                    annotated_sequence_annotations_manual += '1'\n",
    "                else:\n",
    "                    align_annotation_annotated_sequence += '0'\n",
    "                    annotated_sequence_annotations_manual += '0'\n",
    "                annotated_count += 1\n",
    "            else:\n",
    "                align_annotation_annotated_sequence += '-'\n",
    "\n",
    "        #print(align_annotation_target)\n",
    "        #print(format_alignment(*alignment))\n",
    "        #print(align_annotation_annotated_sequence)\n",
    "        #print(target_sequence_annotations)\n",
    "        #print(target_sequence)\n",
    "        #print(sequence)\n",
    "        #print(annotated_sequence_annotations)\n",
    "        #print(annotated_sequence_annotations_manual)\n",
    "        #print('\\n')\n",
    "    return is_binding_site"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from zipfile import ZipFile\n",
    "\n",
    "FILE_BEFORE = \"metrics_before_finetune.yaml\"\n",
    "FILE_AFTER = \"metrics.yaml\"\n",
    "\n",
    "def get_metrics_from_zipfile(path):\n",
    "    with ZipFile(path) as zip:\n",
    "        all_files = list(zip.namelist())\n",
    "        metrics_before, metrics_after = {}, {}\n",
    "        for file in tqdm(all_files):\n",
    "            path = os.path.dirname(file)\n",
    "            filename = os.path.basename(file)\n",
    "            if filename == FILE_BEFORE:\n",
    "                with zip.open(file) as file_yaml:\n",
    "                    dic = yaml.load(file_yaml, Loader=yaml.FullLoader)\n",
    "                metrics_before[path] = dic[\"best_epoch_metric_summaries\"][\"test\"]\n",
    "            elif filename == FILE_AFTER:\n",
    "                with zip.open(file) as file_yaml:\n",
    "                    dic = yaml.load(file_yaml, Loader=yaml.FullLoader)\n",
    "                metrics_after[path] = dic[\"best_epoch_metric_summaries\"][\"test\"]\n",
    "    return metrics_before, metrics_after"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "output_name = 'images_1head'\n",
    "if not os.path.exists(output_name):\n",
    "    os.mkdir(output_name)\n",
    "input_name = 'binding_db_DGN_ESM_models_finetuned_finetune_all_lr0.0001_loss-mse_heads-4'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17675/17675 [01:43<00:00, 170.20it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_before, metrics_after = get_metrics_from_zipfile(\n",
    "    'data/binding_db_DGN_ESM_models_finetuned_finetune_all_lr0.0001_loss-mse_heads-4.zip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "names = os.listdir(f'data/{input_name}')\n",
    "pearsonRs = []\n",
    "for name in tqdm(names):\n",
    "    try:\n",
    "        pearsonRs.append(metrics_after[f'data/{input_name}/{name}/default/version_0']['pearsonr/test'])\n",
    "    except:\n",
    "        pearsonRs.append(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 1000.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score\n",
    "\n",
    "print(pearsonRs)\n",
    "for name, pearsonR in tqdm(zip(names, pearsonRs)):\n",
    "    if pearsonR < 0.82: continue\n",
    "    attention_weights_name = os.path.join(input_name, name, 'default/version_0/attn_weights_test_head_0.csv')\n",
    "\n",
    "    csv_input = pd.read_csv(attention_weights_name)\n",
    "    csv_input = csv_input.sort_values(by=['preds-0'], ascending=False)\n",
    "    #csv_input = csv_input.drop(csv_input.index[range(10,len(csv_input))])\n",
    "    query_sequences = list(set(csv_input['proteins_seq'].tolist()))\n",
    "    for query_idx, query_sequence in enumerate(query_sequences):\n",
    "        seq_info = binding_db.loc[binding_db['BindingDB Target Chain  Sequence'] == query_sequence]\n",
    "        complex_ids_repeated = seq_info['PDB ID(s) for Ligand-Target Complex'].dropna().tolist()\n",
    "        complex_ids = list(set([pdbid for repeated in complex_ids_repeated for pdbid in str(repeated).split(',')]))\n",
    "        if complex_ids == []: continue\n",
    "        target_ids_repeated = seq_info['PDB ID(s) of Target Chain'].dropna().tolist()\n",
    "        target_ids = list(set([pdbid for repeated in target_ids_repeated for pdbid in str(repeated).split(',')]))\n",
    "        comp_and_target_ids = list(set(complex_ids) | set(target_ids))\n",
    "        has_target = anno.loc[anno['PDBID'].isin(comp_and_target_ids)]\n",
    "        has_target_by_sequence = anno.loc[anno['sequence'].isin(query_sequences)]\n",
    "        sequences = has_target['sequence'].tolist()\n",
    "\n",
    "        all_alignments = []\n",
    "        for sequence in sequences:\n",
    "            try:\n",
    "                alignments = pairwise2.align.globalxx(query_sequence, sequence)\n",
    "                all_alignments.append(alignments[0])\n",
    "            except:\n",
    "                continue\n",
    "        if all_alignments == []: continue\n",
    "\n",
    "        scores = [alignment.score for alignment in all_alignments]\n",
    "        top3_misalginment_scores = sorted(list(set(-np.array(scores) + len(query_sequence))))[:3]\n",
    "        misaligned_allowance = top3_misalginment_scores[-1]\n",
    "\n",
    "        alignment_ratio = 0.01  # This is the percentage of a sequence that needs to be aligned to the original sequence to include its binding sites\n",
    "\n",
    "        row = csv_input.loc[csv_input['proteins_seq'] == query_sequence]\n",
    "\n",
    "        for top_k in [3, 5, 10, 20, 30, 50]:\n",
    "            attention = np.array(row.values.tolist())\n",
    "            attention = attention[:, 7:len(query_sequence) + 7].astype(float)[:top_k]\n",
    "            attention_mean = attention.mean(axis=0)\n",
    "            attention_mean = attention_mean / attention_mean.max()\n",
    "            #attention_mean = attention_mean > 0.3\n",
    "            #softmax_mean = np.exp(attention_mean) / sum(np.exp(attention_mean))\n",
    "            #attention_mean = attention_mean / attention_mean.sum()\n",
    "            top_prediction_idx = attention_mean.argsort()[-3:][::-1]\n",
    "            top_predictions = np.zeros_like(attention_mean)\n",
    "            top_predictions[np.array(top_prediction_idx)] = 1\n",
    "\n",
    "            repeats = int(np.ceil(attention.shape[0] / 30))\n",
    "            is_binding_site = binding_site_annotation(all_alignments, has_target_frame=has_target,\n",
    "                                                      input_sequence=query_sequence)\n",
    "\n",
    "            roc_auc = roc_auc_score(is_binding_site, top_predictions)\n",
    "            avgP = average_precision_score(is_binding_site, top_predictions)\n",
    "            true_pos_rate = precision_score(is_binding_site, top_predictions)\n",
    "            random_idx = np.random.randint(0, len(is_binding_site), size=3)\n",
    "            random = np.zeros_like(is_binding_site)\n",
    "            random[random_idx] = 1\n",
    "            randomAvgP = average_precision_score(is_binding_site, random)\n",
    "            random_true_positive_rate = precision_score(is_binding_site, random)\n",
    "            is_binding_site = is_binding_site.astype(int)\n",
    "            top_predictions = top_predictions.astype(int)\n",
    "            preds_dist1 = realign(is_binding_site, top_predictions, dist=1).astype(int)\n",
    "            preds_dist2 = realign(is_binding_site, top_predictions, dist=2).astype(int)\n",
    "            preds_dist3 = realign(is_binding_site, top_predictions, dist=3).astype(int)\n",
    "            avgP1 = average_precision_score(is_binding_site, preds_dist1)\n",
    "            avgP2 = average_precision_score(is_binding_site, preds_dist2)\n",
    "            avgP3 = average_precision_score(is_binding_site, preds_dist3)\n",
    "            true_pos_rate1 = precision_score(is_binding_site, preds_dist1)\n",
    "            true_pos_rate2 = precision_score(is_binding_site, preds_dist2)\n",
    "            true_pos_rate3 = precision_score(is_binding_site, preds_dist3)\n",
    "            visualization = np.concatenate(\n",
    "                [np.tile(is_binding_site, (repeats, 1)), np.tile(attention_mean, (repeats, 1)), attention], axis=0)\n",
    "            ax = sn.heatmap(visualization, annot=False, cmap='pink', cbar=False)\n",
    "            plt.title(\n",
    "                f'name: {name} \\n prot: {query_idx} pearsonR: {round(pearsonR, 2)} avgP: {round(avgP, 2)} randAvgP: {round(randomAvgP, 2)} TPR: {round(true_pos_rate, 2)} randTPR: {round(random_true_positive_rate, 2)} \\n avgP1: {round(avgP1,2)} avgP2: {round(avgP2,2)} avgP3: {round(avgP3,2)} TPR1: {round(true_pos_rate1,2)} TPR2: {round(true_pos_rate2,2)} TPR3: {round(true_pos_rate3,2)} \\n avgP1: {round(avgP1,2)} avgP2: {round(avgP2,2)} avgP3: {round(avgP3,2)} TPR1: {round(true_pos_rate1,2)} TPR2: {round(true_pos_rate2,2)} TPR3: {round(true_pos_rate3,2)}')\n",
    "            ax.hlines([repeats * 2], *ax.get_xlim())\n",
    "            plt.savefig(\n",
    "                f'{output_name}/{name}_prot{query_idx}_top{top_k}_pearsonR{round(pearsonR, 2)}_avgP{round(avgP, 2)}_tpr{round(true_pos_rate, 2)}.jpg')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            #break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}